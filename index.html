<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
    <title>Hyunju Kim üåù</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no,
  maximum-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>



</head>
<body>

    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="#In-Progress">In-Progress</a></li>
                    <li><a href="#publications">Publications</a></li>
                    <li><a href="#">CV</a></li>
                </ul>
            </div> 
        </div>
    </nav>

    <!-- Page Content -->
    <div class="container">

        <div class="row">

            <!-- Entries Column -->
            <div class="col-md-8">
                <h2 id="Home">About me</h2>

                <div style="margin-top:3%; text-align:justify;">
                    <p>
                        Hello! üåº
                        I am a Ph.D. student in Information Science at Cornell University. My research aims to articulate telepresence by designing remote collaboration tools.
                    </p>

                    <p>
                        As inspiring HCI researcher, my research goal is to investigate how to facilitate interaction between humans using Extended Reality or robotic embodiment, connecting these interactions from virtual space to real space. I have been developing VR/AR systems to support remote collaboration and analyzing nonverbal behaviors. Furthermore, I have been working on investigating the influence of robotic or virtual embodiment on physical and cognitive abilities.
                    </p>

                    <p>
                        Prior to joining Cornell, I worked as a Research Assistant at the AI & Robot Institute at KIST (Korea Institute of Science and Technology). I earned my Master's degree in Culture Technology from KAIST in 2019, and my Bachelor's degree in Electrical Engineering from Ewha Womans University in 2017.
                    </p>

                    <p>
                        Beyond my studies, I love exploring new destinations üß≥, trying out new activities üöÄ, and adding to my collection of badges & postcards üíå! I'm always on the lookout for my next thrilling journey.
                    </p>

                </div>

                <h2 id="In-Progress"> In-Progress</h2>

                <div style="margin-top:3%; text-align:justify;">
                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Exploring the Influence of Representation in Asymmetric Telepresence System</strong><br />
                            Remote collaboration techniques often involve immersive methods for some collaborators, while others employ robotic surrogates to engage with remote counterparts. 
                            The choice between a physical robot and a virtual avatar as a representation raises questions about the balance between realism and flexibility.
                            This study investigates which representation, whether a physical robot or a virtual avatar, is more effective for local collaborators, particularly in terms of their perception of remote users.
                            It also explores how these representations impact copresence, specifically regarding peripheral awareness and understanding of the dynamics in remote collaboration.<br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Extended Reflection: Enhancing Teachers‚Äô Reflective Practices through XR</strong><br />
                            This study examines the use of Extended Reality (XR) as a tool to enhance teachers' self-reflection on their nonverbal instructional techniques.
                            Through experimentation with ten teachers using two XR prototypes, Immersive XR and VR Desktop, participants reviewed their previous teaching sessions to assess their interactions with students of varying engagement levels. <br />
                            <img style="border:0px solid black" class="img-responsive" src="Extended_Reflection.png" width="700" height="360" alt=""><br /><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>XR as Remote Demonstration Methodology for Hardware Prototyping: A Reflexive Approach</strong><br />
                            This paper advocates for the adoption of extended reality (XR) as a remote demonstration method for evaluating human-computer interaction (HCI) prototypes.
                            By utilizing XR, researchers can broaden the audience and accessibility of their demonstrations without compromising the essence of the user experience.
                            Drawing on ethnographic reflexivity, the paper introduces three key functionalities of remote XR demonstrations.
                            This proposal underscores the efficacy of reflexive demonstrations and enriches the repertoire of remote HCI evaluation techniques. <br />
                            <img style="border:1px solid black" class="img-responsive" src="XRDemonstration.png" width="700" height="360" alt=""><br /><br />
                        </li>
                    </ul>


                    <!--<a href="https://www.tandfonline.com/doi/pdf/10.1080/10447318.2023.2188533" target="_blank">
        <img style="border:1px solid black" src="DualAwareness.png" width="360" height="180" onmouseover="this.src='mouserover.png';" onmouseout="this.src='DualAwareness.png';">
    </a>

    <a href="https://lh3.googleusercontent.com/drive-viewer/AAOQEOQ5n5JfrB9hQ_pGVa6ylK9qxVQtlV2Mfj6gfCLrf-0cg7TV3Sv6MniI9bOhrSwCTJwnNr5HrD_jEg2qDtCv-LBNXcX6KQ=s1600?source=screenshot.guru" target="_blank">
        <img style="border:1px solid black" src="CC.png" width="360" height="180" top="570px" left="360px" onmouseover="this.src='CC_2.png';" onmouseout="this.src='CC.png';">
    </a>

    <br />


    <iframe width="360" height="180"
            src="https://www.youtube.com/embed/ErNNrySTF9g">
    </iframe>

    <iframe width="360" height="180"
            src="https://www.youtube.com/embed/AnGQq0RJw0U">
    </iframe>-->

                </div>


                <h2 id="publications">Publications</h2>


                <div style="margin-top:3%; text-align:justify;">
                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>VRoxy: Enabling Remote Collaboration in Large Spaces Beyond Local Boundaries via a VR-Driven Robotic Proxy</strong><br />
                            Mose Sakashita, <em>Hyunju Kim</em>, Brandon J Woodard, Ruidong Zhang, Fran√ßois Guimbreti√®re<br />
                            Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. 2023. <a href="#" target="_blank">To appear</a><br />

                            <!--<img style="border:1px solid black" class="img-responsive" src="DualAwareness.png" width="600" height="360" alt=""><br /><br />-->
                        </li>

                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Providing Dual Awareness using Multimodal Cues for Collaborative Manipulation in Virtual Environments</strong><br />
                            <em>Hyunju Kim</em> and Jung-Min Park<br />
                            International Journal of Human‚ÄìComputer Interaction, 2023, 1-15. <a href="https://www.tandfonline.com/doi/pdf/10.1080/10447318.2023.2188533" target="_blank">Download</a><br />
                            <!--<img style="border:1px solid black" class="img-responsive" src="DualAwareness.png" width="600" height="360" alt=""><br /><br />-->
                        </li>

                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Comparing the Impact of Professional and Automatic Closed Captions on Video-Watching Experience </strong><br />
                            <em>Hyunju Kim</em>, Yan Tao, Chuanrui Liu, Yuzhuo Zhang, Yuxin Li<br />
                            Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems, 2023. <a href="https://dl.acm.org/doi/10.1145/3544549.3585634" target="_blank">Download</a><br />
                            <!--<img style="border:1px solid black" class="img-responsive" src="intro_film.png" width="600" height="360" alt=""><br /><br />-->
                            <!--<img src="intro_film.png" width="600" height="180">-->
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>ReMotion: Supporting Remote Collaboration in Open Space with Automatic Robotic Embodiment </strong><br />
                            Mose Sakashita, Ruidong Zhang, Xiaoyi Li, <em>Hyunju Kim</em>, Michael Russo, Cheng Zhang, Malte F. Jung, Fran√ßois Guimbreti√®re<br />
                            Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 2023. p. 1-14. <a href="https://dl.acm.org/doi/10.1145/3544548.3580699" target="_blank">Download</a><br />
                            <!--<iframe width="600" height="360"
                    src="https://www.youtube.com/embed/ErNNrySTF9g">
            </iframe>-->
                        </li>
                    </ul>


                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong> Human-Centered Dynamic Service Scheduling Approach in Multi-Agent Environments </strong><br />
                            Yunseo Jung, <em>Hyunju Kim</em>, Kyung-Duk Suh, Jung-Min Park<br />
                            Applied Sciences, 2022, 12.21: 10850. <a href="https://www.mdpi.com/2076-3417/12/21/10850/pdf" target="_blank">Download</a>
                            <!--<img src="robot-scheduling.png" width="600" height="180">-->
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>RealityBrush: an AR authoring system that captures and utilizes kinetic properties of everyday objects</strong><br />
                            <em>Hyunju Kim</em>, Sanghwa Hong, Junki Kim, Taesoo Jang, Woontaek Woo, Seongkook Heo, Byungjoo Lee<br />
                            Multimedia Tools and Applications, 2021, 80: 31135-31158. <a href="https://link.springer.com/article/10.1007/s11042-020-09332-4" target="_blank">Download</a><br />
                            <!--<iframe width="600" height="360"
                    src="https://www.youtube.com/embed/AnGQq0RJw0U">
            </iframe>-->
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Button++ Designing Risk-aware Smart Buttons</strong><br />
                            Eunji Park, <em>Hyunju Kim</em>, Byungjoo Lee<br />
                            Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems, 2018, p.1-6. <a href="https://dl.acm.org/doi/pdf/10.1145/3170427.3188645" target="_blank">Download</a>
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>A Study on the Effect of Inter Key Spacing on Typing Performance</strong><br />
                            <em>Hyunju Kim</em>, Eunji Park, Byungjoo Lee<br />
                            HCI Korea, 2018, pp.394-398. <a href="https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE07401422" target="_blank">Download</a>
                        </li>
                    </ul>

                </div>



                <!--<h2 id="Projects">Projects</h2>

                <div style="margin-top:3%; text-align:justify;">
                    <iframe width="640" height="360"
                    <a href="https://www.tandfonline.com/doi/pdf/10.1080/10447318.2023.2188533" height="5" width="10" target="_blank">
                        <img src="DualAwareness.png" alt=" Dual Awareness (2023) ">
                        <a>
                    </iframe>




                    <iframe width="640" height="360"
                            src="https://www.youtube.com/embed/AnGQq0RJw0U">
                    </iframe>
                    <p><b>RealityBrush (2021)</b></p>-->
                <!--</div>-->

            </div>


            <!-- Contact Info on the Sidebar -->
            <div class="col-md-4" style="margin-top:2%">

                <!-- Main Image -->
                <img class="img-responsive" src="photo.png" alt=""><br>

                <div style="font-family: 'sans-serif', sans-serif; font-size: 20px;"><b>Hyunju Kim üåù</b></div><br>
                <p><b>hyunjukim@infosci.cornell.edu</b><br>
                <p>
                    Ph.D. in Information Science<br>
                    Cornell University @Ithaca, NY<br>
                </p>
                <dd><a href="mailto:hyunjukim@infosci.cornell.edu" target="_blank">‚úâÔ∏è Email</a></dd>
                <dd><a href="https://scholar.google.com/citations?hl=en&user=2zyuLVEAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">üéì Google Scholar</a></dd>
                <dd><a href="https://www.linkedin.com/in/hyunju-kim-789491253/" target="_blank">üîó LinkedIn</a></dd>
                <dd><a href="https://twitter.com/Hyunju__Kim" target="_blank">üê¶ Twitter</a></dd>
                <dd><a href="https://www.instagram.com/hyun_juui/" target="_blank">üëæ Instagram</a></dd>


            </div>


            <!-- Links on the Sidebar -->
            <!--<div class="col-md-4" style="margin-top:2%">
            </div>-->

        </div>


    </div>
    <!-- /.container -->
    <!-- Other people may like it too! -->
    <a style="color:#b5bec9;font-size:0.8em; float:right;" href="https://github.com/mavroudisv/plain-academic">Plain Academic</a>

</body>

</html>
