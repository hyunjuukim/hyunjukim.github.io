<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->

<html lang="en">
<head>
    <title>Hyunju Kim üåù</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no,
  maximum-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>



</head>
<body>

    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="#publications">Publications</a></li>
                    <li><a href="#Projects">Projects</a></li>
                    <li><a href="#Teaching Experience">Teaching Experience</a></li>
                </ul>
            </div> 
        </div>
    </nav>

    <!-- Page Content -->
    <div class="container">

        <div class="row">

            <!-- Entries Column -->
            <div class="col-md-8">
                <h2 id="Home">About me</h2>

                <div style="margin-top:3%; text-align:justify;">
                    <p>
                        Hello! üåº
                        I am a Ph.D. student in Information Science at Cornell University, advised by Fran√ßois Guimbreti√®re. My research aims to design collaboration tools that support digital-physical convergence.
                    </p>

                    <p>
                        I believe advanced spatial convergence will be pervasive in various contexts, such as hybrid meetings, ubiquitous environments, or human-robot collaboration. Through designing tools for supporting this convergence, I would like to understand socio-spatial interactions between humans. Therefore, I would like to not only build collaboration tools but also conduct empirical studies to understand human interactions.
                    </p>

                    <p>
                        Prior to joining Cornell, I worked as a Research Assistant at the AI & Robot Institute at KIST (Korea Institute of Science and Technology). I earned my Master's degree in Culture Technology from KAIST in 2019, and my Bachelor's degree in Electrical Engineering from Ewha Womans University in 2017.
                    </p>

                    <p>
                        Beyond my studies, I love exploring new destinations üß≥, trying out new activities üöÄ, and adding to my collection of badges & postcards üíå! I'm always on the lookout for my next thrilling journey.
                    </p>

                    <br /><br /><br />

                </div>


                <h2 id="publications">Publications</h2>


                <div style="margin-top:3%; text-align:justify;">
                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>VRoxy: Enabling Remote Collaboration in Large Spaces Beyond Local Boundaries via a VR-Driven Robotic Proxy</strong><br />
                            Mose Sakashita, <strong><em>Hyunju Kim</em></strong>, Brandon J Woodard, Ruidong Zhang, Fran√ßois Guimbreti√®re<br />
                            Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, 2023. <a href="https://dl.acm.org/doi/10.1145/3586183.3606743" target="_blank">Download</a><br /><br />
                        </li>

                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Providing Dual Awareness using Multimodal Cues for Collaborative Manipulation in Virtual Environments</strong><br />
                            <strong><em>Hyunju Kim</em></strong> and Jung-Min Park<br />
                            International Journal of Human‚ÄìComputer Interaction, 2023, 1-15. <a href="https://www.tandfonline.com/doi/pdf/10.1080/10447318.2023.2188533" target="_blank">Download</a><br /><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Comparing the Impact of Professional and Automatic Closed Captions on Video-Watching Experience </strong><br />
                            <strong><em>Hyunju Kim</em></strong>, Yan Tao, Chuanrui Liu, Yuzhuo Zhang, Yuxin Li<br />
                            Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems, 2023. <a href="https://dl.acm.org/doi/10.1145/3544549.3585634" target="_blank">Download</a><br /><br />
                            <!--<img style="border:0px solid black" class="img-responsive" src="CCPoster.png" width="650" height="360" alt=""><br />-->

                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>ReMotion: Supporting Remote Collaboration in Open Space with Automatic Robotic Embodiment </strong><br />
                            Mose Sakashita, Ruidong Zhang, Xiaoyi Li, <strong><em>Hyunju Kim</em></strong>, Michael Russo, Cheng Zhang, Malte F. Jung, Fran√ßois Guimbreti√®re<br />
                            Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 2023. p. 1-14. <a href="https://dl.acm.org/doi/10.1145/3544548.3580699" target="_blank">Download</a><br /><br />
                        </li>
                    </ul>


                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong> Human-Centered Dynamic Service Scheduling Approach in Multi-Agent Environments </strong><br />
                            Yunseo Jung, <strong><em>Hyunju Kim</em></strong>, Kyung-Duk Suh, Jung-Min Park<br />
                            Applied Sciences, 2022, 12.21: 10850. <a href="https://www.mdpi.com/2076-3417/12/21/10850/pdf" target="_blank">Download</a><br /><br />
                            <!--<img src="robot-scheduling.png" width="600" height="180">-->
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>RealityBrush: an AR authoring system that captures and utilizes kinetic properties of everyday objects</strong><br />
                            <strong><em>Hyunju Kim</em></strong>, Sanghwa Hong, Junki Kim, Taesoo Jang, Woontaek Woo, Seongkook Heo, Byungjoo Lee<br />
                            Multimedia Tools and Applications, 2021, 80: 31135-31158. <a href="https://link.springer.com/article/10.1007/s11042-020-09332-4" target="_blank">Download</a><br /><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>Button++ Designing Risk-aware Smart Buttons</strong><br />
                            Eunji Park, <strong><em>Hyunju Kim</em></strong>, Byungjoo Lee<br />
                            Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems, 2018, p.1-6. <a href="https://dl.acm.org/doi/pdf/10.1145/3170427.3188645" target="_blank">Download</a><br /><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>A Study on the Effect of Inter Key Spacing on Typing Performance</strong><br />
                            <strong><em>Hyunju Kim</em></strong>, Eunji Park, Byungjoo Lee<br />
                            HCI Korea, 2018, pp.394-398. <a href="https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE07401422" target="_blank">Download</a><br /><br />
                        </li>
                    </ul>

                    <br /><br /><br />
                </div>



                <h2 id="Projects"> Projects</h2>

                <div style="margin-top:3%; text-align:justify;">
                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <h4>Exploring the Influence of Representation in Asymmetric Telepresence System</h4>
                            <em> In-Progress</em><br />
                            Remote collaboration techniques often involve immersive methods for some collaborators, while others employ robotic surrogates to engage with remote counterparts.
                            The choice between a physical robot and a virtual avatar as a representation raises questions about the balance between realism and flexibility.
                            This study investigates which representation, whether a physical robot or a virtual avatar, is more effective for local collaborators, particularly in terms of their perception of remote users.
                            It also explores how these representations impact copresence, specifically regarding peripheral awareness and understanding of the dynamics in remote collaboration.<br /><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <h4>Extended Reflection: Enhancing Teachers‚Äô Reflective Practices through XR</h4>
                            <em> In-Progress</em><br />
                            This study examines the use of Extended Reality (XR) as a tool to enhance teachers' self-reflection on their nonverbal instructional techniques.
                            Through experimentation with ten teachers using two XR prototypes, Immersive XR and VR Desktop, participants reviewed their previous teaching sessions to assess their interactions with students of varying engagement levels. <br />
                            <img style="border:0px solid black" class="img-responsive" src="Extended_Reflection.png" width="700" height="360" alt=""><br /><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <h4> XR as Remote Demonstration Methodology for Hardware Prototyping: A Reflexive Approach</h4>
                            <em> In-Progress</em><br />
                            This paper advocates for the adoption of extended reality (XR) as a remote demonstration method for evaluating human-computer interaction (HCI) prototypes.
                            By utilizing XR, researchers can broaden the audience and accessibility of their demonstrations without compromising the essence of the user experience.
                            Drawing on ethnographic reflexivity, the paper introduces three key functionalities of remote XR demonstrations.
                            This proposal underscores the efficacy of reflexive demonstrations and enriches the repertoire of remote HCI evaluation techniques. <br /><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <h4> VRoxy: Enabling Remote Collaboration in Large Spaces Beyond Local Boundaries via a VR-Driven Robotic Proxy </h4>
                            <iframe width="700" height="360" src="https://www.youtube.com/embed/1hpaASC_Xls?si=tJwOXgB-5MqV6loa"> </iframe>
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <h4>Providing Dual Awareness using Multimodal Cues for Collaborative Manipulation in Virtual Environments</h4>
                            <img style="border:0px solid black" class="img-responsive" src="DualAwareness.png" width="700" height="360" alt=""><br />
                        </li>
                    </ul>

                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <h4>ReMotion: Supporting Remote Collaboration in Open Space with Automatic Robotic Embodiment</h4>
                            <iframe width="700" height="360" src="https://www.youtube.com/embed/ErNNrySTF9g"></iframe>
                        </li>
                    </ul>


                    <ul>
                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <h4>RealityBrush: an AR authoring system that captures and utilizes kinetic properties of everyday objects</h4>
                            <iframe width="700" height="360" src="https://www.youtube.com/embed/AnGQq0RJw0U"> </iframe>
                        </li>
                    </ul>

                    <br /><br /><br />

                    <h2 id="Teaching Experience">Teaching Experience</h2>
                    <div style="margin-top:3%; text-align:justify;">
                        <h4> Teaching Assistant at Cornell</h4>

                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>INFO 6520</strong>: Human Computer Interaction Graduate Studio ____________
                            <em> Fall 2023 </em>
                        </li>

                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>INFO 2950</strong>: Introduction to Data Science _________________________
                            <em> Spring 2023 </em>
                        </li>
                        <br />

                        <h4> Teaching Assistant at KAIST</h4>

                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>GCT 700</strong>:  Research Methodology of Human Behavioral Science _______
                            <em> Fall 2018 </em>
                        </li>

                        <li class="paper" words="Collaborative manipulation, awareness, multimodal interaction">
                            <strong>CTP 471</strong>: Social Networks Theory _______________________________
                            <em> Spring 2017 </em>
                        </li>
                    </div>
                </div>



                <br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />

            </div>



            <!-- Contact Info on the Sidebar -->
            <div class="col-md-4" style="margin-top:2%">

                <!-- Main Image -->
                <img class="img-responsive" src="photo.png" alt=""><br>

                <div style="font-family: 'sans-serif', sans-serif; font-size: 20px;"><b>Hyunju Kim üåù</b></div><br>
                <p><b>hyunjukim@infosci.cornell.edu</b><br>
                <p>
                    Ph.D. in Information Science<br>
                    Cornell University @Ithaca, NY<br>
                </p>
                <dd><a href="mailto:hyunjukim@infosci.cornell.edu" target="_blank">‚úâÔ∏è Email</a></dd>
                <dd><a href="https://scholar.google.com/citations?hl=en&user=2zyuLVEAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">üéì Google Scholar</a></dd>
                <dd><a href="https://www.linkedin.com/in/hyunju-kim-789491253/" target="_blank">üîó LinkedIn</a></dd>
                <dd><a href="https://twitter.com/hyunjus_twit" target="_blank">üê¶ Twitter</a></dd>
                <dd><a href="https://www.instagram.com/hyun_juui/" target="_blank">üëæ Instagram</a></dd>
                <dd><a href="#" target="_blank">üìÑ CV</a></dd>


            </div>

            <!-- Links on the Sidebar -->
            <!--<div class="col-md-4" style="margin-top:2%">
    </div>-->

        </div>


    </div>
    <!-- /.container -->
    <!-- Other people may like it too! -->
    <a style="color:#b5bec9;font-size:0.8em; float:right;" href="https://github.com/mavroudisv/plain-academic">Plain Academic</a>

</body>

</html>
